{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Generate ML Annotations\n",
    "\n",
    "Author: Nardiena A. Pratama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-python\n",
    "!sudo apt-get update && sudo apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helper_scripts.annotation_generation_func import *\n",
    "from helper_scripts.utility_functions import *\n",
    "from PIL import Image, ImageFont\n",
    "import torchvision.transforms as transforms\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current notebook directory\n",
    "notebook_dir = os.path.dirname(os.path.abspath(''))\n",
    "\n",
    "# Construct the path to folder1\n",
    "folder1_path = os.path.abspath(os.path.join(notebook_dir, '..', '..', 'winter-research-2023'))\n",
    "\n",
    "# Add folder1 to the system path\n",
    "sys.path.append(folder1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confidence level for object detection model\n",
    "CONF_LEVEL_DEC= 0.5\n",
    "CONF_LEVEL = int(CONF_LEVEL_DEC *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_code = True # set to False when wanting to run model inference in this notebook\n",
    "eval_obj_det_model = True  # set to True when wanting to run the object detection model\n",
    "eval_img_capt_model =  True  # set to True when wanting to run the image captioning model\n",
    "output_dir = f\"/data/outputs_{CONF_LEVEL}\"\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AWS Credentials\n",
    "\n",
    "Do not put quotation marks around the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=aws_bucket_name\n",
    "%env S3_OUTPUT_PREFIX=link_to_s3_bucket_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session using the default credentials (IAM role attached to the instance)\n",
    "session = boto3.Session()\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Specify your bucket name and folder path\n",
    "bucket_name = os.getenv('BUCKET_NAME')\n",
    "folder_path = '/data/'\n",
    "\n",
    "# Initialize variables for pagination\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=folder_path)\n",
    "\n",
    "# List to store all CSV file keys\n",
    "csv_files = []\n",
    "\n",
    "# Iterate through each page of results\n",
    "for page in page_iterator:\n",
    "    for obj in page.get('Contents', []):\n",
    "        key = obj['Key']\n",
    "        # Check if the key ends with '.csv' and is directly in the specified folder\n",
    "        if key.endswith('.csv') and not key.count('/') != folder_path.count('/') and not key.endswith('resultswithgoodworkeronly.csv'):\n",
    "            csv_files.append(key)\n",
    "print(csv_files)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Read each CSV file into a pandas DataFrame and store in a list\n",
    "categories_dataframes = {}\n",
    "for file_key in csv_files:\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    csv_content = response['Body'].read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_content))\n",
    "    df_key = file_key.split(\".csv\")[0].split(folder_path)[-1]\n",
    "    categories_dataframes[df_key] = df\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(categories_dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = list(categories_dataframes.keys())\n",
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check images in folder and Image IDs from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in CATEGORIES:\n",
    "    df_count = len(categories_dataframes[cat])\n",
    "    count = 0\n",
    "\n",
    "    # Specify your bucket name and folder path\n",
    "    folder_path = f'/data/{cat}/'\n",
    "    \n",
    "    # Initialize variables for pagination\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=folder_path)\n",
    "\n",
    "\n",
    "    # Iterate through each page of results\n",
    "    for page in page_iterator:\n",
    "        for obj in page.get('Contents', []):\n",
    "            if obj['Key'].endswith('.jpg'):\n",
    "                count += 1\n",
    "                \n",
    "    if df_count == count:\n",
    "        print(f\"SUCCESS: {cat} DOES HAVE equal number of image IDs and existing images\")\n",
    "    else:\n",
    "        print(f\"WARNING: {cat} DOES NOT HAVE equal number of image IDs and existing images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"labels\": '../data/coco-labels-paper.txt',\n",
    "    \"model\":'frcnn-resnet',\n",
    "    \"confidence\": CONF_LEVEL,\n",
    "}\n",
    "obj_det_model_dict = getMLModel(model_type=\"object-detection\", args=args)\n",
    "\n",
    "img_capt_model_dict = getMLModel(model_type=\"image-captioning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAUTION! \n",
    "\n",
    "#### Running the code below will result in ML labels that may contain different results as the ML models are non-deterministic. This will alter the results in the subsequent Jupyter notebooks.\n",
    "\n",
    "#### Skip the rest of the cells below and move on to the next Jupyter notebook to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not skip_code:\n",
    "    for category in CATEGORIES:\n",
    "        obj_det_labels = {}\n",
    "        img_capt_labels = {}\n",
    "        obj_det_labels[category] = {}\n",
    "        img_capt_labels[category] = {}\n",
    "\n",
    "         # Specify your bucket name and folder path\n",
    "        folder_path = f'/data/{category}/'\n",
    "        \n",
    "        # Initialize variables for pagination\n",
    "        paginator = s3.get_paginator('list_objects_v2')\n",
    "        page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=folder_path)\n",
    "    \n",
    "        annotations_output_dir = f\"{output_dir}/annotated-{category}/\"\n",
    "        if not check_s3_path_exists(bucket_name, annotations_output_dir):\n",
    "            print(f\"The directory {annotations_output_dir} does not exist in the bucket {bucket_name}. Creating directory...\")\n",
    "            s3.put_object(Bucket=bucket_name, Key=annotations_output_dir)\n",
    "            \n",
    "        # Iterate through each page of results\n",
    "        for page in page_iterator:\n",
    "            for obj in page.get('Contents', []):\n",
    "                if obj['Key'].endswith('.jpg'):\n",
    "                    img_id = (obj['Key'].split('.jpg')[0]).split(\"/\")[-1] # (file.split('_')[-1].split('.')[0])\n",
    "                    file_path = obj['Key']\n",
    "                    \n",
    "                    try:\n",
    "\n",
    "                        # Download the image from S3\n",
    "                        response = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "                        image_data = response['Body'].read()\n",
    "                        \n",
    "                        # Read the image using PIL\n",
    "                        raw_image = Image.open(BytesIO(image_data)).convert('RGB')\n",
    "                    \n",
    "                        if eval_obj_det_model:\n",
    "                            WEIGHTS = obj_det_model_dict[\"weights\"]\n",
    "                            model = obj_det_model_dict[\"model\"]\n",
    "                            DEVICE = obj_det_model_dict[\"device\"]\n",
    "                            args = obj_det_model_dict[\"args\"]\n",
    "                            \n",
    "                            # Initialise inference transforms\n",
    "                            preprocess = WEIGHTS.transforms()\n",
    "\n",
    "                            transform = transforms.Compose([\n",
    "                                            transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "                                            transforms.ConvertImageDtype(torch.uint8)  # Ensure the tensor is in uint8 format\n",
    "                                        ])\n",
    "                            image_tensor = transform(raw_image)\n",
    "                            img = image_tensor.to(DEVICE)\n",
    "                            # img = (img * 255).byte() # make sure tensor is in uint8 format\n",
    "                            \n",
    "                            # Apply inference preprocessing transforms\n",
    "                            batch = [preprocess(img)]\n",
    "                            model.eval()\n",
    "                            prediction = model(batch)[0]\n",
    "\n",
    "                            color_blind_palette = [\n",
    "                                \"#FF3D00\",  # neon red\n",
    "                                \"#FF6F00\",  # neon orange\n",
    "                                \"#FFD600\",  # neon yellow\n",
    "                                \"#00E676\",  # neon green\n",
    "                                \"#00B0FF\",  # neon blue\n",
    "                                \"#D5006D\",  # neon pink\n",
    "                                \"#FF4081\",  # neon magenta\n",
    "                                \"#F50057\",  # neon rose\n",
    "                                \"#FF5252\",  # neon coral\n",
    "                                \"#76FF03\",  # neon lime\n",
    "                                \"#1B5E20\",  # neon dark green\n",
    "                                \"#5E57FF\",  # neon purple\n",
    "                                \"#02FEE4\"   # neon cyan\n",
    "                            ]\n",
    "                            \n",
    "                            # Create a color map using the color-blind friendly palette\n",
    "                            class_color_map = {\n",
    "                                int(class_id): color_blind_palette[int(class_id) % len(color_blind_palette)]\n",
    "                                for class_id in set(prediction[\"labels\"])\n",
    "                            }\n",
    "                            \n",
    "                            labels = []\n",
    "                            img_labels = []\n",
    "                            img_boxes = []\n",
    "                            for pred_label, pred_conf, pred_box in zip(prediction[\"labels\"], prediction[\"scores\"], prediction[\"boxes\"]):\n",
    "                                if pred_conf > args[\"confidence\"]:\n",
    "                                    img_labels.append(\"{}: {:.2f}%\".format(WEIGHTS.meta[\"categories\"][pred_label], pred_conf * 100))\n",
    "                                    img_boxes.append(pred_box)\n",
    "                                    labels.append(WEIGHTS.meta[\"categories\"][pred_label])\n",
    "\n",
    "                            stacked_boxes = torch.stack(img_boxes)\n",
    "                            \n",
    "                            labels_str = ','.join(set(labels))\n",
    "                            obj_det_labels[category][img_id] = labels_str\n",
    "                            # font_type = ImageFont.truetype(\"winter-research-2023/Arial.ttf\", 50, encoding=\"unic\")\n",
    "                            font_path = '/tmp/Arial.ttf'\n",
    "                            # font_type = ImageFont.truetype(font_path, 50)\n",
    "\n",
    "                            box = draw_bounding_boxes(img, boxes=stacked_boxes,\n",
    "                                                    labels=img_labels,\n",
    "                                                    colors=[class_color_map[int(class_id)] for class_id in prediction[\"labels\"]],\n",
    "                                                    width=4, font_size=50, font=font_path)\n",
    "                            im = to_pil_image(box.detach())\n",
    "                            # im.show()   \n",
    "                            # im.save(f\"{annotations_output_dir}/annotated_{img_id}.jpg\")\n",
    "                            s3_file_path = f\"{annotations_output_dir}annotated_{img_id}.jpg\"\n",
    "                            upload_image_to_s3(bucket_name, s3_file_path, im)\n",
    "                        if eval_img_capt_model:\n",
    "                            processor = img_capt_model_dict[\"processor\"]\n",
    "                            model = img_capt_model_dict[\"model\"]\n",
    "                            inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "                            out = model.generate(**inputs, max_new_tokens=512)\n",
    "                            caption_str = processor.decode(out[0], skip_special_tokens=True)\n",
    "                            img_capt_labels[category][img_id] = caption_str\n",
    "\n",
    "                    except Exception as err:\n",
    "                        print(f\"error - image {file_path} is corrupted! Skipping image...\")\n",
    "                        print(f\"Error: {err}\")\n",
    "                        # continue\n",
    "\n",
    "        if obj_det_labels:\n",
    "            s3_pickle_path = f\"{output_dir}/{category}_ml_labels_dict_{datetime.now().strftime('%m-%d-%Y')}.pickle\"\n",
    "            upload_pickle_to_s3(bucket_name, s3_pickle_path, obj_det_labels)\n",
    "\n",
    "        if img_capt_labels:\n",
    "            s3_pickle_path = f\"{output_dir}/{category}_ml_captions_dict_{datetime.now().strftime('%m-%d-%Y')}.pickle\"\n",
    "            upload_pickle_to_s3(bucket_name, s3_pickle_path, img_capt_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)\n",
    "print(CONF_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_ids = dict()\n",
    "id_count = dict()\n",
    "for curr_category in CATEGORIES:\n",
    "    id_count[curr_category] = dict()\n",
    "    \n",
    "    # 50%\n",
    "    CONF_LEVEL = 50\n",
    "    output_dir = f'/data/outputs_{CONF_LEVEL}'\n",
    "    file_key_labels = f'{output_dir}/{curr_category}_ml_labels_dict_12-09-2024.pickle'\n",
    "    file_key_captions = f'{output_dir}/{curr_category}_ml_captions_dict_12-09-2024.pickle'\n",
    "    \n",
    "    \n",
    "    caption_results = read_pickle_from_s3(s3, bucket_name, file_key_labels)\n",
    "    label_results = read_pickle_from_s3(s3, bucket_name, file_key_captions)\n",
    "\n",
    "    df = categories_dataframes[curr_category]\n",
    "    \n",
    "    df['id'] = df['id'].astype(str).str.strip().str.lower().apply(lambda x: re.sub(r'\\s+', '', x))\n",
    "    unique_all_ids = set(df['id'].tolist())\n",
    "\n",
    "    \n",
    "    # Clean and standardize IDs in caption_results\n",
    "    unique_caption_ids = set(map(lambda x: re.sub(r'\\s+', '', str(x).strip().lower()), caption_results[curr_category].keys()))\n",
    "\n",
    "    unique_label_ids = set(map(lambda x: re.sub(r'\\s+', '', str(x).strip().lower()), label_results[curr_category].keys()))\n",
    "\n",
    "    intersection_unique_ml_ids = unique_caption_ids.intersection(unique_label_ids)\n",
    "\n",
    "    missing_ids[curr_category] = list(unique_all_ids - intersection_unique_ml_ids)\n",
    "\n",
    "    assert len(missing_ids[curr_category]) == len(unique_all_ids) - len(intersection_unique_ml_ids)\n",
    "    id_count[curr_category][\"before\"] = len(unique_all_ids)\n",
    "    id_count[curr_category][\"after\"] = len(intersection_unique_ml_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ids_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in missing_ids.items()]))\n",
    "missing_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_buffer = StringIO()\n",
    "missing_ids_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3_file_path = f'{output_dir}/missing_ids_all_{CONF_LEVEL}.csv'\n",
    "\n",
    "# Upload the CSV to S3\n",
    "if not skip_code:\n",
    "    s3.put_object(Bucket=bucket_name, Key=s3_file_path, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"DataFrame saved as CSV and uploaded to {output_dir} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_count_df = pd.DataFrame(id_count).T\n",
    "id_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_buffer = StringIO()\n",
    "id_count_df.to_csv(csv_buffer, index=True)\n",
    "\n",
    "s3_file_path = f'{output_dir}/id_count_{CONF_LEVEL}.csv'\n",
    "\n",
    "# Upload the CSV to S3\n",
    "if not skip_code:\n",
    "    s3.put_object(Bucket=bucket_name, Key=s3_file_path, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"DataFrame saved as CSV and uploaded to {output_dir} successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ML Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q25(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def q75(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "# Define income groups\n",
    "def income_group(row):\n",
    "    if row['income'] >= row['min'] and row['income'] < row['q25']:\n",
    "        return 'min-q25'\n",
    "    elif row['income'] >= row['q25'] and row['income'] < row['median']:\n",
    "        return 'q25-median'\n",
    "    elif row['income'] >= row['median'] and row['income'] < row['q75']:\n",
    "        return 'median-q75'\n",
    "    else:\n",
    "        return 'q75-max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_quantiles_get_counts(df, curr_category):\n",
    "    # Calculate quantiles for each region\n",
    "    grouped = df.groupby('region')['income'].agg(['min', q25, 'median', q75, 'max']).reset_index()\n",
    "    \n",
    "    # Merge the quantiles back to the original DataFrame\n",
    "    merged_df = pd.merge(df, grouped, on='region', suffixes=('', '_quantile'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    merged_df['income_group'] = merged_df.apply(income_group, axis=1)\n",
    "    \n",
    "    # Count the number of rows that fulfill each region and income group\n",
    "    group_counts = merged_df.groupby(['region', 'income_group']).size().reset_index(name='count')\n",
    "    print(f\"Count of samples per region and income level for {curr_category.capitalize()} category...\")\n",
    "    return group_counts, merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Number of Rows Grouped by Region and Income Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_categories_dataframes = dict()\n",
    "for curr_category in CATEGORIES:\n",
    "    # if curr_category == 'sleeping':\n",
    "    df = categories_dataframes[curr_category]\n",
    "    \n",
    "    filtered_df = df[~df['id'].isin(missing_ids[curr_category])].copy()\n",
    "    filtered_categories_dataframes[curr_category] = filtered_df.copy()\n",
    "\n",
    "    group_counts = calc_quantiles_get_counts(filtered_df, curr_category)[0]\n",
    "    print(group_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Unique Image IDs From Every Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dw = set(filtered_categories_dataframes['drinking-water']['id'].tolist())\n",
    "print(len(dw))\n",
    "dc = set(filtered_categories_dataframes['drying-clothes']['id'].tolist())\n",
    "print(len(dc))\n",
    "fd = set(filtered_categories_dataframes['front-doors']['id'].tolist())\n",
    "print(len(fd))\n",
    "hw = set(filtered_categories_dataframes['hand-washing']['id'].tolist())\n",
    "print(len(hw))\n",
    "kc = set(filtered_categories_dataframes['kitchens']['id'].tolist())\n",
    "print(len(kc))\n",
    "lr = set(filtered_categories_dataframes['living-rooms']['id'].tolist())\n",
    "print(len(lr))\n",
    "pfd = set(filtered_categories_dataframes['places-for-dinner']['id'].tolist())\n",
    "print(len(pfd))\n",
    "wc = set(filtered_categories_dataframes['washing-clothes']['id'].tolist())\n",
    "print(len(wc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Image IDs that Exist in More Than One Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_list = [dw,dc,fd, hw, kc, lr, pfd, wc]\n",
    "sets = {'dw': dw, 'dc' :dc, 'fd':fd,'hw':hw, 'kc':kc, 'lr':lr,'pfd':pfd, 'wc':wc}\n",
    "\n",
    "# Check for overlapping IDs\n",
    "all_ids = {}\n",
    "overlapping_ids = set()\n",
    "overlapping_locations = {}\n",
    "\n",
    "for set_name, s in sets.items():\n",
    "    for id in s:\n",
    "        if id in all_ids:\n",
    "            overlapping_ids.add(id)\n",
    "            if id in overlapping_locations:\n",
    "                overlapping_locations[id].append(set_name)\n",
    "            else:\n",
    "                overlapping_locations[id] = [all_ids[id], set_name]\n",
    "        else:\n",
    "            all_ids[id] = set_name\n",
    "\n",
    "# Create a dictionary where the key is the overlapping ID and the value is a list of sets it exists in\n",
    "overlapping_dict = {id: overlapping_locations[id] for id in overlapping_ids}\n",
    "\n",
    "# Print the result\n",
    "if overlapping_ids:\n",
    "    print(f\"Overlapping IDs found: {overlapping_ids}\")\n",
    "    for id in overlapping_ids:\n",
    "        print(f\"ID {id} found in sets: {overlapping_locations[id]}\")\n",
    "else:\n",
    "    print(\"No overlapping IDs found. All IDs are unique across the sets.\")\n",
    "\n",
    "print(overlapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Category Abbreviations to Original Category Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name_mapping = {\n",
    "    'dw': 'drinking-water',\n",
    "    'dc': 'drying-clothes',\n",
    "    'fd': 'front-doors',\n",
    "    'hw': 'hand-washing',\n",
    "    'kc': 'kitchens',\n",
    "    'lr': 'living-rooms',\n",
    "    'pfd': 'places-for-dinner',\n",
    "    'sl': 'sleeping',\n",
    "    'wc': 'washing-clothes'\n",
    "}\n",
    "\n",
    "for key, value in overlapping_dict.items():\n",
    "    overlapping_dict[key] = [set_name_mapping[abbr] for abbr in value]\n",
    "\n",
    "print(overlapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Overlapping Image IDs From One of the Categories (the set with fewer overall samples/the set with the smallest region total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = {('living-rooms', 'places-for-dinner'): 'places-for-dinner',\n",
    "                ('drying-clothes', 'washing-clothes'): 'washing-clothes',\n",
    "                ('hand-washing', 'washing-clothes'): 'hand-washing',\n",
    "                ('drinking-water', 'hand-washing'): 'hand-washing',\n",
    "                ('kitchens', 'places-for-dinner'): 'places-for-dinner'}\n",
    "\n",
    "print(len(filtered_categories_dataframes['places-for-dinner']))\n",
    "no_dups_dfs = filtered_categories_dataframes.copy()\n",
    "print(len(no_dups_dfs['places-for-dinner']))\n",
    "for image_id, value in overlapping_dict.items():\n",
    "    if (value[0], value[1]) in cols_to_drop:\n",
    "        drop_col = cols_to_drop[(value[0], value[1])]\n",
    "        no_dups_dfs[drop_col] = no_dups_dfs[drop_col].drop(no_dups_dfs[drop_col][no_dups_dfs[drop_col]['id'] == image_id].index, inplace=False)\n",
    "\n",
    "print(len(filtered_categories_dataframes['places-for-dinner']))\n",
    "print(len(no_dups_dfs['places-for-dinner']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Out Total Samples Per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, each in filtered_categories_dataframes.items():\n",
    "    print(f\"{df_name}: {len(each)}\")\n",
    "print(\"======================== AFTER REMOVING DUPLICATES ========================\")\n",
    "for df_name, each in no_dups_dfs.items():\n",
    "    print(f\"{df_name}: {len(each)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Total Samples By Region and Income and Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downsampled_categories_df = dict()\n",
    "for curr_category in CATEGORIES:\n",
    "    df = no_dups_dfs[curr_category]\n",
    "    \n",
    "    group_counts, merged_df_curr = calc_quantiles_get_counts(df, curr_category)\n",
    "    print(group_counts)\n",
    "    smallest_num_sample = group_counts.groupby('income_group')['count'].min().min()\n",
    "    print(f\"Downsampling to {smallest_num_sample}...\")\n",
    "    temp_downsampled_df = merged_df_curr.groupby(['region', 'income_group'], as_index=False).apply(lambda x: x.sample(n=smallest_num_sample, replace=False), include_groups=False).reset_index(drop=True)\n",
    "    downsampled_categories_df[curr_category] = temp_downsampled_df.merge(no_dups_dfs[curr_category], \n",
    "                                                                         how=\"inner\").drop(['min', 'q25', \n",
    "                                                                                            'median', 'q75', 'max'], axis=1)\n",
    "    assert len(temp_downsampled_df) == len(downsampled_categories_df[curr_category]), f\"Number of rows in downsampled DF ({len(temp_downsampled_df)}) does not match number of rows in merged downsampled DF ({len(downsampled_categories_df[curr_category])})!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out Total Samples Per Category (Again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, each in filtered_categories_dataframes.items():\n",
    "    print(f\"{df_name}: {len(each)}\")\n",
    "print(\"======================== AFTER REMOVING DUPLICATES ========================\")\n",
    "for df_name, each in no_dups_dfs.items():\n",
    "    print(f\"{df_name}: {len(each)}\")\n",
    "print(\"======================== AFTER DOWNSAMPLING ========================\")\n",
    "for df_name, each in downsampled_categories_df.items():\n",
    "    print(f\"{df_name}: {len(each)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Downsampled Dataframes into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_category in CATEGORIES:\n",
    "\n",
    "    print(curr_category)   \n",
    "    curr_df = downsampled_categories_df[curr_category].copy()\n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    curr_df.to_csv(csv_buffer, index=False)\n",
    "    \n",
    "    s3_file_path = f'{output_dir}/downsampled_df_{CONF_LEVEL}_{curr_category}.csv'\n",
    "    \n",
    "    # Upload the CSV to S3\n",
    "    if not skip_code:\n",
    "        s3.put_object(Bucket=bucket_name, Key=s3_file_path, Body=csv_buffer.getvalue())\n",
    "    \n",
    "    print(f\"DataFrame saved as CSV and uploaded to {s3_file_path} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = set(downsampled_categories_df['drinking-water']['id'].tolist())\n",
    "print(len(dw))\n",
    "dc = set(downsampled_categories_df['drying-clothes']['id'].tolist())\n",
    "print(len(dc))\n",
    "fd = set(downsampled_categories_df['front-doors']['id'].tolist())\n",
    "print(len(fd))\n",
    "hw = set(downsampled_categories_df['hand-washing']['id'].tolist())\n",
    "print(len(hw))\n",
    "kc = set(downsampled_categories_df['kitchens']['id'].tolist())\n",
    "print(len(kc))\n",
    "lr = set(downsampled_categories_df['living-rooms']['id'].tolist())\n",
    "print(len(lr))\n",
    "pfd = set(downsampled_categories_df['places-for-dinner']['id'].tolist())\n",
    "print(len(pfd))\n",
    "wc = set(downsampled_categories_df['washing-clothes']['id'].tolist())\n",
    "print(len(wc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(dw.union(dc).union(fd).union(hw).union(kc).union(lr).union(pfd).union(wc))) == (len(dw)+ len(dc)+len(fd)+len(hw)+len(kc)+len(lr)+len(pfd)+len(wc) ):\n",
    "    print(\"SUCCESS: No duplicates found in final dataframe!\")\n",
    "else:\n",
    "    print(\"FAIL: Duplicates found in final dataframe! Make sure that all cells are not run more than once as it can overwrite variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add S3 Image Links to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_s3_link(row, curr_category):\n",
    "    url_prefix = os.getenv('S3_OUTPUT_PREFIX')\n",
    "    return f\"{url_prefix}//data/{curr_category}/{row['id']}.jpg\"\n",
    "\n",
    "for curr_category in CATEGORIES:\n",
    "\n",
    "    print(curr_category)   \n",
    "    curr_df = downsampled_categories_df[curr_category].copy()\n",
    "\n",
    "    curr_df['image_s3_link'] = curr_df.apply(lambda row: add_image_s3_link(row, curr_category), axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    csv_buffer = StringIO()\n",
    "    curr_df.to_csv(csv_buffer, index=False)\n",
    "    \n",
    "    s3_file_path = f'{output_dir}/downsampled_df_with_imagelink_{CONF_LEVEL}_{curr_category}.csv'\n",
    "    print(s3_file_path)\n",
    "                \n",
    "    # Upload the CSV to S3\n",
    "    if not skip_code:\n",
    "        s3.put_object(Bucket=bucket_name, Key=s3_file_path, Body=csv_buffer.getvalue())\n",
    "\n",
    "    print(f\"DataFrame with image s3 links saved as CSV and uploaded to {s3_file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter-research-2023-gMOHPFxi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
