{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Convert Annotations to Embeddings\n",
    "\n",
    "\n",
    "Author: Nardiena A. Pratama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wordsegment autocorrect \n",
    "!pip install spacy==3.8.0\n",
    "!python -m spacy download en_core_web_trf\n",
    "!pip install wandb seaborn \n",
    "!pip install 'sentence-transformers==3.0.1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "import re\n",
    "from helper_scripts.utility_functions import *\n",
    "from helper_scripts.preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AWS Credentials\n",
    "\n",
    "Do not put quotation marks around the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=aws_bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session using the default credentials (IAM role attached to the instance)\n",
    "session = boto3.Session()\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Specify your bucket name\n",
    "bucket_name = os.getenv('BUCKET_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "s3_model_path = \"/data/outputs_50/models/finetuning_all-MiniLM-L12-v2/v1\"  # Make sure this matches with the path to your saved embedding model\n",
    "\n",
    "local_model_dir = \"models/finetuning_all-MiniLM-L12-v2/v1\"  # create a local directory to save the model files\n",
    "\n",
    "# Download model files from S3\n",
    "download_model_from_s3(bucket_name, s3_model_path, local_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_minilm12 = 'models/finetuning_all-MiniLM-L12-v2/v1' # 5 epochs\n",
    "\n",
    "\n",
    "model = SentenceTransformer(local_model_dir)\n",
    "\n",
    "model_name = 'finetuning_all-MiniLM-L12-v2'\n",
    "\n",
    "\n",
    "print(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = \"/data/outputs_50/final_combined_ml_human.csv\"\n",
    "response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "csv_content = response['Body'].read().decode('utf-8')\n",
    "labelled_data = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "labelled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_data[\"ml_object_embed\"]= labelled_data.apply(lambda x: make_embedding(x[\"ml_labels\"], model), axis=1)\n",
    "labelled_data[\"ml_caption_embed\"]= labelled_data.apply(lambda x: make_embedding(x[\"ml_captions\"], model), axis=1)\n",
    "labelled_data[\"human_embed\"]= labelled_data.apply(lambda x: make_embedding(x[\"human_labels\"], model), axis=1)\n",
    "\n",
    "\n",
    "labelled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data[['ml_labels','ml_captions', 'human_labels']].iloc[2]['ml_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_buffer = StringIO()\n",
    "labelled_data.to_csv(csv_buffer, index=False)\n",
    "\n",
    "\n",
    "file_path = f\"/data/outputs_50/{model_name}_embeddings.csv\"\n",
    "# s3.put_object(Bucket=bucket_name, Key=file_path, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"DataFrame saved as CSV and uploaded to {file_path} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scratch_distilroberta_jan3_icwsm25_embeddings.csv\n",
    "# finetuning_all-MiniLM-L6-v2_jan3_icwsm25_embeddings.csv\n",
    "# finetuning_all-MiniLM-L6-v2_jan7_icwsm25_embeddings.csv\n",
    "# all-distilroberta-v1_embeddings\n",
    "key = f\"/data/outputs_50/{model_name}_embeddings.csv\"\n",
    "print(key)\n",
    "response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "csv_content = response['Body'].read().decode('utf-8')\n",
    "labelled_data_embed = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "labelled_data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_data_embed[\"ml_object_embed\"]= labelled_data_embed.apply(lambda x: convert_str_to_array(x[\"ml_object_embed\"]), axis=1)\n",
    "labelled_data_embed[\"ml_caption_embed\"]= labelled_data_embed.apply(lambda x: convert_str_to_array(x[\"ml_caption_embed\"]), axis=1)\n",
    "labelled_data_embed[\"human_embed\"]= labelled_data_embed.apply(lambda x: convert_str_to_array(x[\"human_embed\"]), axis=1)\n",
    "labelled_data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labelled_data_embed[\"ml_object_embed\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten embeddings and add all into list for t-SNE visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ml_object_embed\", \"ml_caption_embed\", \"human_embed\"]\n",
    "tsne_arr = []\n",
    "\n",
    "for col in columns:\n",
    "    temp_arr = []\n",
    "    for idx, row in labelled_data_embed.iterrows():\n",
    "        temp_arr.append(row[col].reshape(-1).tolist())\n",
    "        # print(np.array(temp_arr).shape)\n",
    "    tsne_arr.append(temp_arr)\n",
    "    # print(np.array(tsne_arr).shape)\n",
    "tsne_arr = np.array(tsne_arr)\n",
    "tsne_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml_obj = tsne_arr[0]\n",
    "data_ml_capt = tsne_arr[1]\n",
    "data_human_lab = tsne_arr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "perplexities = [5, 10]\n",
    "learning_rates = [10, 100, 200, 500, 1000]\n",
    "n_iter = [250, 500, 1000]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "combined_data = np.vstack((data_ml_obj, data_ml_capt, data_human_lab))\n",
    "\n",
    "for perplexity in perplexities:\n",
    "    for lr in learning_rates:\n",
    "        for iters in n_iter:\n",
    "            tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=lr, max_iter=iters, random_state=42)\n",
    "            tsne_result = tsne.fit_transform(combined_data)\n",
    "\n",
    "            # Example: Evaluating based on Kullback-Leibler divergence (lower is better)\n",
    "            kl_divergence = tsne.kl_divergence_\n",
    "            \n",
    "            if kl_divergence < best_score:\n",
    "                best_score = kl_divergence\n",
    "                best_params = {'perplexity': perplexity, 'learning_rate': lr, 'n_iter': iters}\n",
    "\n",
    "print(f\"Best Parameters: {best_params} with KL Divergence: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD - learning rate: 'auto', perplexity: 5\n",
    "# NEW - Best Parameters: {'perplexity': 5, 'learning_rate': 1000, 'n_iter': 1000} with KL Divergence: 0.30165356397628784\n",
    "\n",
    "tsne = TSNE(n_components=2, learning_rate=best_params['learning_rate'],\n",
    "                  init='pca', \n",
    "                  perplexity=best_params['perplexity'], \n",
    "                  max_iter=best_params['n_iter'], \n",
    "                  random_state=27) #42\n",
    "tsne_result = tsne.fit_transform(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split points for each dataset in the combined data\n",
    "num_ml_obj = len(data_ml_obj)\n",
    "num_ml_capt = len(data_ml_capt)\n",
    "num_human_lab = len(data_human_lab)\n",
    "\n",
    "# Split the tsne_result back into the original datasets\n",
    "tsne_ml_obj = tsne_result[:num_ml_obj]\n",
    "tsne_ml_capt = tsne_result[num_ml_obj:num_ml_obj + num_ml_capt]\n",
    "tsne_human_lab = tsne_result[num_ml_obj + num_ml_capt:]\n",
    "\n",
    "df_ml_obj = pd.DataFrame(tsne_ml_obj, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_ml_obj['Annotation Type'] = 'ML Object Labels'\n",
    "\n",
    "df_ml_capt = pd.DataFrame(tsne_ml_capt, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_ml_capt['Annotation Type'] = 'ML Captions'\n",
    "\n",
    "df_human_lab = pd.DataFrame(tsne_human_lab, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_human_lab['Annotation Type'] = 'Human Labels'\n",
    "\n",
    "df_tsne = pd.concat([df_ml_obj, df_ml_capt, df_human_lab], ignore_index=False)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('t-SNE Visualization of Embeddings', fontsize=20)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"Annotation Type\",\n",
    "    palette=sns.color_palette(palette='bright', n_colors=3, desat=1),\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Set axis labels and font size\n",
    "plt.xlabel(\"t-SNE Component 1\", fontsize=16)\n",
    "plt.ylabel(\"t-SNE Component 2\", fontsize=16)\n",
    "\n",
    "# Customize tick labels' font size\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Customize legend font size\n",
    "plt.legend(title=\"Annotation Type\", title_fontsize=18, fontsize=16\n",
    "           , bbox_to_anchor=(0.5, -0.15), loc='upper center',\n",
    "           markerscale=2 \n",
    "          )\n",
    "\n",
    "\n",
    "plt.savefig(f\"figs/{model_name}_tsne_visualisation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"figs/{model_name}_tsne_visualisation.svg\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to AWS\n",
    "local_directory = \"figs/\"  # Local directory to upload\n",
    "s3_directory = f\"/data/outputs_50/figs/\"  # S3 path where the directory will be uploaded\n",
    "\n",
    "upload_directory(local_directory, bucket_name, s3_directory, s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(tsne_ml_obj[:, 0], tsne_ml_obj[:, 1], color='b', label='ML Object Labels', alpha=0.5)\n",
    "plt.scatter(tsne_ml_capt[:, 0], tsne_ml_capt[:, 1], color='tab:orange', label='ML Captions', alpha=0.5)\n",
    "plt.scatter(tsne_human_lab[:, 0], tsne_human_lab[:, 1], color='g', label='Human Labels', alpha=0.5)\n",
    "\n",
    "plt.title('t-SNE Visualization of Columns')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(title='Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_ml_obj[0].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "ids = [f'ID_{i}' for i in range(len(labelled_data))]  # Replace with your actual IDs\n",
    "\n",
    "df_ml_obj = pd.DataFrame(tsne_ml_obj, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_ml_obj['Column'] = 'ML Object Labels'\n",
    "\n",
    "df_ml_obj['ID'] = ids\n",
    "\n",
    "df_ml_capt = pd.DataFrame(tsne_ml_capt, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_ml_capt['Column'] = 'ML Captions'\n",
    "df_ml_capt['ID'] = ids\n",
    "\n",
    "df_human_lab = pd.DataFrame(tsne_human_lab, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_human_lab['Column'] = 'Human Labels'\n",
    "\n",
    "df_human_lab['ID'] = ids\n",
    "\n",
    "df_tsne = pd.concat([df_ml_obj, df_ml_capt, df_human_lab], ignore_index=False)\n",
    "\n",
    "custom_colors = {\n",
    "    'ML Object Labels': 'blue',\n",
    "    'ML Captions': 'blue',\n",
    "    'Human Labels': 'blue',\n",
    "    'TEST': 'red'\n",
    "}\n",
    "# Plotting with Plotly\n",
    "fig = px.scatter(df_tsne, x='tsne-2d-one', y='tsne-2d-two', color='Column', \n",
    "                 hover_name='ID', \n",
    "                 hover_data={'Column': True, \n",
    "                             # 'Info': True, \n",
    "                             'tsne-2d-one': False, 'tsne-2d-two': False}, \n",
    "                title='t-SNE Visualization with IDs')\n",
    "fig.update_traces(textposition='top center')  # Adjust text position if needed\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Below is for Testing Purposes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = [\n",
    "    # \"a person is pouring water into a pink bucket\",\n",
    "    # \"a blue bucket with a white substance\",\n",
    "    # \"water tub,water,soil,bottle,dirty hands\",\n",
    "\n",
    "    # \"person,sink\",\n",
    "    \"a man is washing his hands in a sink\",\n",
    "    # \"water,hand,wash,tap,soap,ring,washbasin,cloth,cleaning,make up,handwashing,save water,hyg enig,scope,tooth cleaning,face cleaning,water,sink,soup,home appliance,water pipe,hand wash,hand cleaning,save water,washing hands,vigorous washing,clean,with soap,sink,water,splash sounds,bar soap,water sound,some,man,tap,cleaning,ring,water,deep clean,use soap for handwash,rub our dirty hands,take time for handwash,wash hand for remove terms,healthy habits,good behaviours for future generation,cleaning hands with soap,teach cleaning method to others,wet hands with water,rub hands palm to palm,palm to palm with fingers interface,backs of fingers to opposing palms with fingers interlocked,clean well so you can eat well,clean hands healthy heart,handwashing good,hand washing and caring go together,all hands to the pump,let your fingers do the washing,be aware wash with care,clean hands can stop terms,hand hygiene makes me feel clean,wash your hands to kill terms,be aware wash with care,give soap a chance when washing your hands,water,sink,tap,hand,soap,towel,ring,hand wash,soap,water tap,hand wash,tissue,man,sink,water,weakness\"\n",
    "\n",
    "]\n",
    "\n",
    "embedding1 = model.encode(sentence1)\n",
    "\n",
    "sentence2 = [\n",
    "    # \"person,frisbee,fire tyrant,bowl\",\n",
    "    # \"a woman is putting something in a bucket\",\n",
    "    # \"water tub, water, soil, bottle, dirty hands\",\n",
    "\n",
    "    # \"person,sink\",\n",
    "    # \"a man is washing his hands in a sink\",\n",
    "    \"water,hand,wash,tap,soap,ring,washbasin,cloth,cleaning,make up,handwashing,save water,hyg enig,scope,tooth cleaning,face cleaning,water,sink,soup,home appliance,water pipe,hand wash,hand cleaning,save water,washing hands,vigorous washing,clean,with soap,sink,water,splash sounds,bar soap,water sound,some,man,tap,cleaning,ring,water,deep clean,use soap for handwash,rub our dirty hands,take time for handwash,wash hand for remove terms,healthy habits,good behaviours for future generation,cleaning hands with soap,teach cleaning method to others,wet hands with water,rub hands palm to palm,palm to palm with fingers interface,backs of fingers to opposing palms with fingers interlocked,clean well so you can eat well,clean hands healthy heart,handwashing good,hand washing and caring go together,all hands to the pump,let your fingers do the washing,be aware wash with care,clean hands can stop terms,hand hygiene makes me feel clean,wash your hands to kill terms,be aware wash with care,give soap a chance when washing your hands,water,sink,tap,hand,soap,towel,ring,hand wash,soap,water tap,hand wash,tissue,man,sink,water,weakness\"\n",
    "\n",
    "]\n",
    "\n",
    "embedding2 = model.encode(sentence2)\n",
    "similarities = model.similarity(embedding1, embedding2)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
