{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "use_ml_obj = True\n",
    "use_ml_capt = True\n",
    "use_human_labels = False\n",
    "n_jobs = 24\n",
    "embeddings_path = \"/data/outputs_50/finetuning_all-MiniLM-L12-v2_embeddings.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Perform Income Regression Using Embeddings\n",
    "\n",
    "Sources:\n",
    "- https://imbalanced-learn.org/stable/ensemble.html#boosting\n",
    "\n",
    "Author: Nardiena A. Pratama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = \"reg-v3\"\n",
    "run_code = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install imblearn fairlearn joblib seaborn\n",
    "!pip install wordsegment autocorrect \n",
    "!pip install spacy==3.8.0\n",
    "!pip install -U kaleido\n",
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, root_mean_squared_error, r2_score\n",
    "\n",
    "from fairlearn.metrics import demographic_parity_ratio, equalized_odds_ratio\n",
    "\n",
    "\n",
    "from helper_scripts.preprocess import *\n",
    "from helper_scripts.utility_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AWS Credentials\n",
    "\n",
    "Do not put quotation marks around the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=aws_bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session using the default credentials (IAM role attached to the instance)\n",
    "session = boto3.Session()\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Specify your bucket name\n",
    "bucket_name = os.getenv('BUCKET_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS = []\n",
    "if use_ml_obj:\n",
    "    ANNOTATIONS.append(\"ml_object_embed\")\n",
    "if use_ml_capt:\n",
    "    ANNOTATIONS.append(\"ml_caption_embed\")\n",
    "\n",
    "if use_human_labels:\n",
    "    ANNOTATIONS.append(\"human_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = s3.get_object(Bucket=bucket_name, Key=embeddings_path)\n",
    "csv_content = response['Body'].read().decode('utf-8')\n",
    "data = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "# Read the embedding columns as arrays\n",
    "data[\"ml_object_embed\"]= data.apply(lambda x: convert_str_to_array(x[\"ml_object_embed\"]), axis=1)\n",
    "data[\"ml_caption_embed\"]= data.apply(lambda x: convert_str_to_array(x[\"ml_caption_embed\"]), axis=1)\n",
    "data[\"human_embed\"]= data.apply(lambda x: convert_str_to_array(x[\"human_embed\"]), axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data[['id', 'category', 'ml_object_embed','ml_caption_embed', 'human_embed', 'region', 'country', 'income']].copy()\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset['embeddings'] = subset.apply(lambda row: np.concatenate([row[i] for i in ANNOTATIONS]), axis=1)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset_X = subset['embeddings'].apply(lambda x: np.array(x).flatten())\n",
    "subset_X = np.stack(subset_X)\n",
    "\n",
    "subset_y = subset[['income']] \n",
    "regions = subset[['region']]\n",
    "categories = subset[['category']]\n",
    "unique_regions = np.unique(regions)\n",
    "unique_categories = np.unique(categories)\n",
    "\n",
    "\n",
    "subset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, regions_train, regions_test, cats_train, cats_test = train_test_split(subset_X, subset_y, regions, categories, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "y_train_series = pd.DataFrame(y_train)\n",
    "regions_train_series = pd.DataFrame(regions_train)\n",
    "\n",
    "categories_train_series = pd.DataFrame(cats_train)\n",
    "\n",
    "concatenated_df = pd.concat([y_train_series, regions_train_series, categories_train_series], axis=1)\n",
    "\n",
    "concatenated_df.columns = list(concatenated_df.columns[:-3]) + ['target', 'region', 'category']\n",
    "\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[concatenated_df.region == 'Asia']['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[concatenated_df.region == 'The Americas']['target'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Ada Boost Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "assert run_code == True, \"Run code is set to False! Change value to run code below.\"\n",
    "n_runs = 10\n",
    "random_seeds = list(range(n_runs))\n",
    "\n",
    "all_y_predictions = dict()\n",
    "\n",
    "all_scores = dict()\n",
    "all_scores['overall'] = {'rmse': [], 'r2': []}\n",
    "\n",
    "\n",
    "for label in unique_regions:\n",
    "    all_scores[label] = {'rmse': [], 'r2': []}\n",
    "\n",
    "all_scores_category = dict()\n",
    "\n",
    "\n",
    "for curr_cat in unique_categories:\n",
    "    all_scores_category[curr_cat] = {'rmse': [], 'r2': []}\n",
    "\n",
    "for seed in random_seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    parameters = {\n",
    "        'n_estimators': list(range(50,150,50)),\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "        'loss': ['linear', 'square', 'exponential']\n",
    "    }\n",
    "    dt_base_learner = DecisionTreeRegressor(random_state = seed)\n",
    "\n",
    "    adaboostreg = AdaBoostRegressor(estimator=dt_base_learner, \n",
    "                                random_state=seed)\n",
    "    reg = GridSearchCV(adaboostreg, parameters, scoring=\"neg_mean_squared_error\", return_train_score=True, n_jobs=n_jobs)\n",
    "    with joblib.parallel_backend(backend='loky', n_jobs=n_jobs):\n",
    "        reg.fit(X_train, y_train.values.ravel())\n",
    "    print(\"Grid Search CV done...\")\n",
    "    print(\"Training based on best parameters...\")\n",
    "    real_adaboost = AdaBoostRegressor(estimator=DecisionTreeRegressor(\n",
    "                                    random_state=seed),\n",
    "                   learning_rate=reg.best_estimator_.learning_rate,                     \n",
    "                   n_estimators=reg.best_estimator_.n_estimators, \n",
    "                   loss=reg.best_estimator_.loss,\n",
    "                   random_state=seed)\n",
    "    real_adaboost.fit(X_train, y_train.values.ravel())\n",
    "    print(\"Model has been fitted!\")\n",
    "    y_test_predictions = real_adaboost.predict(X_test)\n",
    "    all_y_predictions[seed] = y_test_predictions\n",
    "    overall_rmse = root_mean_squared_error(y_test.values.ravel(), y_test_predictions)\n",
    "    all_scores['overall']['rmse'].append(overall_rmse)\n",
    "    overall_r2 = r2_score(y_test.values.ravel(), y_test_predictions)\n",
    "    all_scores['overall']['r2'].append(overall_r2)\n",
    "    \n",
    "\n",
    "    # Calculate RMSE for each region\n",
    "    for region in unique_regions:\n",
    "        # Mask for the current region\n",
    "        mask = regions_test == region\n",
    "\n",
    "        class_rmse = root_mean_squared_error(y_test.values[mask],\\\n",
    "                                y_test_predictions[mask.values.ravel()])\n",
    "        class_r2 = r2_score(y_test.values[mask],\\\n",
    "                                y_test_predictions[mask.values.ravel()])\n",
    "        all_scores[region]['rmse'].append(class_rmse)\n",
    "        all_scores[region]['r2'].append(class_r2)\n",
    "\n",
    "    for curr_cat in unique_categories:\n",
    "        # Mask for the current region\n",
    "        mask = cats_test == curr_cat\n",
    "\n",
    "        class_rmse = root_mean_squared_error(y_test.values[mask],\\\n",
    "                                y_test_predictions[mask.values.ravel()])\n",
    "        class_r2 = r2_score(y_test.values[mask],\\\n",
    "                                y_test_predictions[mask.values.ravel()])\n",
    "        all_scores_category[curr_cat]['rmse'].append(class_rmse)\n",
    "        all_scores_category[curr_cat]['r2'].append(class_r2)\n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "# Append relevant terms based on the flags\n",
    "if use_ml_obj:\n",
    "    parts.append('ml_obj')\n",
    "if use_ml_capt:\n",
    "    parts.append('ml_capt')\n",
    "if use_human_labels:\n",
    "    parts.append('human_labels')\n",
    "\n",
    "# Join the parts with underscores\n",
    "annotations_used_underscore = '_'.join(parts)\n",
    "annotations_used = \" \".join(annotations_used_underscore.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = annotations_used.title()\n",
    "\n",
    "s3_path_all_scores = f'/data/outputs_50/model_outputs/{model_output_dir}/{annotations_used_underscore}_reg_all_scores.pickle'\n",
    "s3_path_all_scores_category = f'/data/outputs_50/model_outputs/{model_output_dir}/{annotations_used_underscore}_reg_all_scores_category.pickle'\n",
    "s3_path_all_y_preds = f'/data/outputs_50/model_outputs/{model_output_dir}/{annotations_used_underscore}_reg_all_y_predictions.pickle'\n",
    "\n",
    "if run_code:\n",
    "    upload_pickle_to_s3(s3, bucket_name, s3_path_all_scores, all_scores)\n",
    "    upload_pickle_to_s3(s3, bucket_name, s3_path_all_scores_category, all_scores_category)\n",
    "    upload_pickle_to_s3(s3, bucket_name, s3_path_all_y_preds, all_y_predictions)\n",
    "\n",
    "else:\n",
    "    all_scores = read_pickle_from_s3(s3, bucket_name, s3_path_all_scores)\n",
    "    all_scores_category = read_pickle_from_s3(s3, bucket_name, s3_path_all_scores_category)\n",
    "    y_test_predictions = read_pickle_from_s3(s3, bucket_name, s3_path_all_y_preds)\n",
    "    y_test_predictions = np.mean(\n",
    "                            np.stack(list(y_test_predictions.values())), axis=0\n",
    "                        )\n",
    "    \n",
    "\n",
    "# Upload to S3\n",
    "buffer = StringIO()\n",
    "\n",
    "# Create the content to upload\n",
    "line = f\"Results for {title}...\\n\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "\n",
    "\n",
    "line = \"============================== Overall RMSE ==============================\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "line = f\"Mean RMSE: {normal_round(np.mean(all_scores['overall']['rmse']),2)}, Standard Deviation: {normal_round(np.std(all_scores['overall']['rmse']),2)}\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "line = f\"Mean R2: {normal_round(np.mean(all_scores['overall']['r2']),2)}, Standard Deviation: {normal_round(np.std(all_scores['overall']['r2']),2)}\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "\n",
    "line = f\"\\n============================= Grouped by Region =============================\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "\n",
    "for cls in unique_regions:\n",
    "    line = f\"\\n============================== {cls} ==============================\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "    line = f\"Mean RMSE: {normal_round(np.mean(all_scores[cls]['rmse']),2)}, Standard Deviation: {normal_round(np.std(all_scores[cls]['rmse']),2)}\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "    line = f\"Mean R2: {normal_round(np.mean(all_scores[cls]['r2']),2)}, Standard Deviation: {normal_round(np.std(all_scores[cls]['r2']),2)}\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "\n",
    "line = f\"\\n============================= Grouped by Image Category =============================\"\n",
    "print(line)\n",
    "buffer.write(line + '\\n')\n",
    "\n",
    "for cls in unique_categories:\n",
    "    line = f\"\\n============================== {cls} ==============================\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "    line = f\"Mean RMSE: {normal_round(np.mean(all_scores_category[cls]['rmse']),2)}, Standard Deviation: {normal_round(np.std(all_scores_category[cls]['rmse']),2)}\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "    line = f\"Mean R2: {normal_round(np.mean(all_scores_category[cls]['r2']),2)}, Standard Deviation: {normal_round(np.std(all_scores_category[cls]['r2']),2)}\"\n",
    "    print(line)\n",
    "    buffer.write(line + '\\n')\n",
    "\n",
    "\n",
    "buffer.seek(0)  # Move to the start of the buffer\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3_key = f'/data/outputs_50/model_outputs/{model_output_dir}/{annotations_used_underscore}_reg_final_results.txt'\n",
    "if run_code:\n",
    "    s3.put_object(Bucket=bucket_name, Key=s3_key, Body=buffer.getvalue())\n",
    "    print(f\"\\nFinal results file created and written successfully into {s3_key}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions == y_test_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(y_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_code = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with ground truth, predicted, and country information\n",
    "df = pd.DataFrame({'Ground Truth': y_test.values.flatten(), 'Predicted': y_test_predictions, \n",
    "                    'Country': subset.loc[y_test.index, 'country'],\n",
    "                    'Continent': subset.loc[y_test.index, 'region']})\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create the interactive scatter plot\n",
    "fig = px.scatter(df, x='Ground Truth', y='Predicted', color='Continent', hover_data=['Country', 'Continent'], template='seaborn')\n",
    "\n",
    "# Add the regression line\n",
    "coefficients = np.polyfit(df['Ground Truth'], df['Predicted'], 1)\n",
    "x_vals = np.array([df['Ground Truth'].min(), df['Ground Truth'].max()])\n",
    "y_vals = np.polyval(coefficients, x_vals)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_vals, y=y_vals, mode='lines', line_shape='linear', name='Best Fit Line', line=dict(color='blue'), line_dash='dot'))\n",
    "\n",
    "# Create the diagonal line trace\n",
    "min_gt_val = df['Ground Truth'].min()\n",
    "max_gt_val = df['Ground Truth'].max()\n",
    "identity_x = np.linspace(min_gt_val, max_gt_val, 100)\n",
    "\n",
    "identity_x_logged = np.log10(identity_x)\n",
    "\n",
    "identity_y = identity_x\n",
    "\n",
    "line_trace = go.Scatter(\n",
    "    x=identity_x,  \n",
    "    y=identity_y,\n",
    "    mode='lines',\n",
    "    line=dict(color='red'),\n",
    "    name='Identity Line'\n",
    ")\n",
    "\n",
    "\n",
    "# Add the diagonal line trace to the scatter plot\n",
    "fig.add_trace(line_trace)\n",
    "\n",
    "\n",
    "\n",
    "title_components = []\n",
    "# Append relevant terms based on the flags\n",
    "if use_ml_obj:\n",
    "    title_components.append(\"ML Objects\")\n",
    "if use_ml_capt:\n",
    "    title_components.append(\"ML Captions\")\n",
    "if use_human_labels:\n",
    "    title_components.append(\"Human Labels\")\n",
    "\n",
    "if len(title_components) > 1:\n",
    "    if len(title_components) == 2:\n",
    "        title = \" and \".join(title_components) \n",
    "    else:\n",
    "        title = \", \".join(title_components[:-1]) + \", and \" + title_components[-1] \n",
    "else:\n",
    "    title = title_components[0] \n",
    "\n",
    "\n",
    "# Update layout for labels and titles\n",
    "fig.update_layout(title=f'{title} Scatter Plot',\n",
    "                  xaxis_title='Ground Truth',\n",
    "                  yaxis_title='Predicted',\n",
    "                  font_size=28,\n",
    "                  showlegend=True,\n",
    "                  hoverlabel=dict(bgcolor='white', font_size=12, font_family='Arial'),\n",
    "                  legend=dict(title='Continent', font = dict(size = 19))\n",
    ")\n",
    "\n",
    "log_ticks = [10**i for i in range(int(np.floor(np.log10(df['Ground Truth'].min()))),\n",
    "                                  int(np.ceil(np.log10(df['Ground Truth'].max()))) + 1)]\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        type=\"log\",\n",
    "        tickvals=log_ticks  # Only show ticks at powers of 10\n",
    "    ),\n",
    "    # yaxis=dict(type=\"log\")\n",
    ")\n",
    "\n",
    "fig.update_traces(marker={'size': 8})\n",
    "\n",
    "fig.update_layout(yaxis_range=[df['Predicted'].min() - 1000, 10000])\n",
    "\n",
    "\n",
    "if run_code:\n",
    "    # Save the figure as PNG to an in-memory binary buffer\n",
    "    buffer = BytesIO()    \n",
    "    fig.write_image(buffer, format=\"png\", width=1355, height=360, scale=2)  # Requires `kaleido` or `orca`\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    s3_file_path = f\"/data/outputs_50/model_outputs/{model_output_dir}/scatter_plot_{annotations_used_underscore}_new.png\"\n",
    "    \n",
    "    # Upload the buffer content to S3\n",
    "    s3.put_object(Body=buffer.getvalue(), Bucket=bucket_name, Key=s3_file_path)\n",
    "    \n",
    "    print(f\"Plot saved to S3 at s3://{bucket_name}/{s3_file_path}\")\n",
    "\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    fig.write_image(buffer, format=\"svg\", width=1355, height=360, scale=2)  # Requires `kaleido` or `orca`\n",
    "    buffer.seek(0)\n",
    "    s3_file_path = f\"/data/outputs_50/model_outputs/{model_output_dir}/scatter_plot_{annotations_used_underscore}_new.svg\"\n",
    "    s3.put_object(Body=buffer.getvalue(), Bucket=bucket_name, Key=s3_file_path)\n",
    "    \n",
    "    print(f\"Plot saved to S3 at s3://{bucket_name}/{s3_file_path}\")\n",
    "\n",
    "    # Close the buffer\n",
    "    buffer.close()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winter-research-2023-gMOHPFxi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
