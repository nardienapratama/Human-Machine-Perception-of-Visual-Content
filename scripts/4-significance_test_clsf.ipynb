{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import normaltest, ttest_ind\n",
    "\n",
    "from helper_scripts.utility_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set AWS Credentials\n",
    "\n",
    "Do not put quotation marks around the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=aws_bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session using the default credentials (IAM role attached to the instance)\n",
    "session = boto3.Session()\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = session.client('s3')\n",
    "\n",
    "# Specify your bucket name\n",
    "bucket_name = os.getenv('BUCKET_NAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Pickle File Containing Results from Human Labels (Worst Overall Classification Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link_to_pickle_file = '/data/outputs_50/model_outputs/clsf-v3/human_labels_clsf_all_scores.pickle'\n",
    "clsf_human = read_pickle_from_s3(s3, bucket_name, link_to_pickle_file)\n",
    "clsf_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Pickle File Containing Results from ML Captions (Best Overall Classification Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link_to_pickle_file = '/data/outputs_50/model_outputs/clsf-v3/ml_capt_clsf_all_scores.pickle'\n",
    "clsf_ml_capt = read_pickle_from_s3(s3, bucket_name, link_to_pickle_file)\n",
    "clsf_ml_capt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = clsf_human['overall_weighted']\n",
    "np.mean(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = clsf_ml_capt['overall_weighted']\n",
    "np.mean(sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['A'] = sample1\n",
    "results['B'] = sample2\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box and Whisker Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.boxplot()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "results.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, p = normaltest(sample1)\n",
    "print(value, p)\n",
    "if p >= 0.05:\n",
    " print('It is likely that result1 is normal')\n",
    "else:\n",
    " print('It is unlikely that result1 is normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, p = normaltest(sample2)\n",
    "print(value, p)\n",
    "if p >= 0.05:\n",
    " print('It is likely that result2 is normal')\n",
    "else:\n",
    " print('It is unlikely that result2 is normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Means for Gaussian Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results1\n",
    "values1 = sample1\n",
    "# load results2\n",
    "values2 = sample2\n",
    "# calculate the significance\n",
    "value, pvalue = ttest_ind(values1, values2, equal_var=False)\n",
    "print(value, pvalue)\n",
    "if pvalue > 0.05:\n",
    "\tprint('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Samples are likely drawn from different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
